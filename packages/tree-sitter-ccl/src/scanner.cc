/**
 * Tree-sitter External Scanner for CCL (Categorical Configuration Language)
 * 
 * This external scanner implements Python-like indentation-based block structure
 * for CCL configuration files. It generates INDENT/DEDENT tokens that allow
 * the main tree-sitter parser to handle nested configuration blocks without
 * explicit delimiters like braces or keywords.
 * 
 * ALGORITHM OVERVIEW:
 * ==================
 * 1. Maintains an indentation stack tracking nested block levels
 * 2. Measures line indentation (spaces + tabs*8) at line boundaries  
 * 3. Generates INDENT tokens when indentation increases (new block)
 * 4. Generates DEDENT tokens when indentation decreases (close blocks)
 * 5. Handles cross-platform newlines (\n, \r\n) with proper line tracking
 * 6. Implements lookahead DEDENT detection for complex parser states
 * 7. Cleans up remaining blocks with DEDENT tokens at EOF
 * 
 * TREE-SITTER INTEGRATION:
 * ========================
 * - External scanners run before the main parser on each token
 * - valid_symbols[] indicates which tokens the parser currently expects
 * - State is serialized/deserialized for incremental parsing
 * - Scanner can consume characters and generate exactly one token per call
 * 
 * CCL SYNTAX EXAMPLE:
 * ===================
 *   server =
 *     host = localhost    # INDENT generated here
 *     port = 8080
 *     config =
 *       debug = true      # Second INDENT for nested block
 *       timeout = 30
 *   # Two DEDENTs generated here to close both blocks
 *   client = ...
 * 
 * CRITICAL DESIGN DECISIONS:
 * ==========================
 * - Base indentation level (0) always remains in stack to prevent underflow
 * - Tab characters count as 8 spaces (standard terminal convention)
 * - DEDENT tokens are queued and emitted one per scan() call
 * - Lookahead detection handles parser states requiring DEDENT before NEWLINE
 * - EOF processing ensures all blocks are properly closed
 * 
 * AUTHORS: CCL Community
 * LICENSE: MIT
 * VERSION: Compatible with tree-sitter 0.20+
 */

#include <tree_sitter/parser.h>
#include <cstdio>
#include <cstring>
#include <vector>
#include <queue>

// Debug logging can be enabled for development and troubleshooting
// Uncomment the first line to enable detailed execution tracing
// #define DEBUG_LOG(fmt, ...) fprintf(stderr, "[SCANNER] " fmt "\n", ##__VA_ARGS__)
#define DEBUG_LOG(fmt, ...)  // Disabled for production builds

namespace {

/**
 * Token types generated by this external scanner.
 * These MUST match the externals declaration in grammar.js exactly.
 * Order matters - these numeric values are used by tree-sitter internally.
 */
enum TokenType {
  NEWLINE,  ///< Line terminators (\n, \r\n) - triggers indentation analysis on next scan
  INDENT,   ///< Increased indentation level - opens a new nested block
  DEDENT    ///< Decreased indentation level - closes one or more nested blocks
};

/**
 * Scanner state machine for indentation-based parsing.
 * 
 * This structure maintains all state needed to track indentation levels
 * across multiple scan() calls and parsing sessions. The state is designed
 * to be efficiently serializable for incremental parsing.
 */
struct Scanner {
  /**
   * Stack of active indentation levels representing nested block structure.
   * 
   * - Always contains at least one element (base level 0)
   * - New levels are pushed when indentation increases (INDENT)
   * - Levels are popped when indentation decreases (DEDENT)
   * - Stack top represents the current expected indentation level
   * 
   * Example for "  server =\n    host = value":
   *   Initial: [0]
   *   After "server =": [0, 2]  
   *   After "host =": [0, 2, 4]
   */
  std::vector<uint16_t> indent_stack;
  
  /**
   * Queue of DEDENT tokens waiting to be emitted.
   * 
   * When indentation decreases multiple levels at once, we need to emit
   * multiple DEDENT tokens. Since scan() can only return one token per call,
   * we queue the extras and return them in subsequent calls.
   * 
   * Example: Indentation goes from level 8 to level 2, passing through [8,4,2]
   *   First call: Generate and queue 2 DEDENTs, return first DEDENT
   *   Second call: Return queued DEDENT from pending_tokens
   */
  std::queue<TokenType> pending_tokens;
  
  /**
   * Flag indicating we're at the start of a line (after NEWLINE or file start).
   * 
   * This is crucial for determining when to measure indentation:
   * - true: We should measure indentation on the next scan() call
   * - false: We're in the middle of a line, don't measure indentation
   * 
   * Set to true by NEWLINE tokens and at scanner initialization.
   * Set to false after measuring indentation or encountering non-whitespace.
   */
  bool at_line_start;
  
  /**
   * Most recently measured indentation level for the current line.
   * 
   * Calculated as: (space_count) + (tab_count * 8)
   * This follows the standard convention where tabs equal 8 spaces.
   * 
   * Updated every time we measure indentation at line start.
   * Used for comparison with indent_stack to determine INDENT/DEDENT generation.
   */
  uint16_t current_indent;

  /**
   * Initialize scanner in the proper starting state.
   * 
   * Starting conditions:
   * - at_line_start = true (we start at the beginning of the first line)
   * - current_indent = 0 (no indentation measured yet)
   * - indent_stack = [0] (base level, prevents stack underflow)
   * - pending_tokens = empty (no queued tokens)
   * 
   * The base indentation level (0) is critical - it ensures we always
   * have a reference point for comparison and prevents stack underflow
   * when popping indentation levels.
   */
  Scanner() : at_line_start(true), current_indent(0) {
    indent_stack.push_back(0); // Base indentation level - NEVER remove this
    DEBUG_LOG("Scanner initialized: base_level=0, at_line_start=true");
  }

  /**
   * Main scanning function implementing the indentation-sensitive parsing algorithm.
   * 
   * This is the core of the external scanner, called by tree-sitter whenever
   * it needs to check for NEWLINE, INDENT, or DEDENT tokens. The function
   * implements a sophisticated state machine with multiple processing phases.
   * 
   * PROCESSING ORDER (CRITICAL for correctness):
   * ============================================
   * 1. PENDING TOKENS: Return any queued DEDENT tokens from previous calls
   * 2. NEWLINE DETECTION: Detect and consume line terminators (\n, \r\n) 
   * 3. LOOKAHEAD DEDENT: Peek ahead to detect needed DEDENTs at line boundaries
   * 4. INDENTATION ANALYSIS: Measure indentation and generate INDENT/DEDENT
   * 5. EOF CLEANUP: Generate remaining DEDENT tokens at end-of-file
   * 6. STATE CLEANUP: Reset line-start flag for non-whitespace characters
   * 
   * TREE-SITTER INTEGRATION:
   * ========================
   * @param lexer - Interface for reading characters and advancing position
   *   - lexer->lookahead: Current character (0 for EOF)
   *   - lexer->advance(lexer, skip): Move to next char, skip=false includes in token
   *   - lexer->result_symbol: Set this to the token type we're returning
   *   - lexer->get_column(): Get current column position (0-based)
   * 
   * @param valid_symbols - Boolean array indicating which tokens parser expects
   *   - valid_symbols[NEWLINE]: Parser wants NEWLINE tokens
   *   - valid_symbols[INDENT]: Parser wants INDENT tokens 
   *   - valid_symbols[DEDENT]: Parser wants DEDENT tokens
   *   - Only generate tokens the parser is expecting!
   * 
   * @return true if we generated a token, false if no token matched
   * 
   * ALGORITHM INVARIANTS:
   * ====================
   * - indent_stack always contains at least base level (0)
   * - Only one token is returned per scan() call
   * - pending_tokens are always processed before new token generation
   * - at_line_start is updated correctly for next call
   * - State changes are atomic (all-or-nothing)
   */
  bool scan(TSLexer *lexer, const bool *valid_symbols) {
    DEBUG_LOG("=== scan() called ===");
    DEBUG_LOG("Lookahead: '%c' (%d)", 
              lexer->lookahead >= 32 ? lexer->lookahead : '?', lexer->lookahead);
    DEBUG_LOG("Valid symbols: NEWLINE=%d INDENT=%d DEDENT=%d", 
              valid_symbols[NEWLINE], valid_symbols[INDENT], valid_symbols[DEDENT]);
    DEBUG_LOG("State: at_line_start=%d, current_indent=%d, stack_size=%zu, stack_top=%d",
              at_line_start, current_indent, indent_stack.size(), 
              indent_stack.empty() ? -1 : indent_stack.back());

    // PHASE 1: Handle pending DEDENT tokens first
    // ============================================
    // CRITICAL: This must be the first check to maintain correct parse order.
    // When indentation decreases multiple levels, we queue multiple DEDENT tokens
    // and emit them one per scan() call. This ensures proper nesting structure.
    // 
    // Example: Indentation 8 -> 0 generates DEDENTs for levels [8,4,2,0]
    //   Call 1: Return DEDENT(8->4), queue DEDENT(4->2) and DEDENT(2->0)
    //   Call 2: Return queued DEDENT(4->2), still have DEDENT(2->0) queued
    //   Call 3: Return queued DEDENT(2->0), queue now empty
    if (!pending_tokens.empty()) {
      TokenType token = pending_tokens.front();
      pending_tokens.pop();
      DEBUG_LOG("Phase 1: Returning pending DEDENT token (queue size now: %zu)", pending_tokens.size());
      lexer->result_symbol = token;
      return true;
    }

    // PHASE 2: Cross-platform NEWLINE detection and consumption
    // ==========================================================
    // Newlines can occur anywhere in the input and always take precedence
    // when the parser expects them. This handles both Unix (\n) and Windows (\r\n)
    // line endings correctly by consuming the appropriate character sequence.
    // 
    // IMPORTANT: Setting at_line_start=true is crucial for the next scan() call
    // to know it should measure indentation.
    if ((lexer->lookahead == '\n' || lexer->lookahead == '\r') && valid_symbols[NEWLINE]) {
      DEBUG_LOG("Phase 2: Found newline character (%c)", lexer->lookahead);
      
      // Consume Windows-style \r\n or Unix-style \n
      // The 'false' parameter includes these characters in the token
      if (lexer->lookahead == '\r') {
        lexer->advance(lexer, false);  // Consume \r
        // Handle optional \n after \r for Windows CRLF line endings
        if (lexer->lookahead == '\n') {
          lexer->advance(lexer, false);  // Consume \n
        }
      } else {
        lexer->advance(lexer, false);  // Consume \n
      }
      
      // CRITICAL: Mark that we're now at the start of a new line
      // This triggers indentation measurement on the next scan() call
      at_line_start = true;
      lexer->result_symbol = NEWLINE;
      DEBUG_LOG("Phase 2: Returning NEWLINE token, at_line_start=true for next call");
      return true;
    }

    // PHASE 3: Lookahead DEDENT detection - Advanced tree-sitter pattern
    // ===================================================================
    // PROBLEM: Sometimes the parser needs DEDENT tokens before NEWLINE tokens,
    // but we can't know if DEDENT is needed until we see the next line's indentation.
    // 
    // SOLUTION: When we're at a newline with DEDENT expected but NEWLINE not expected,
    // peek ahead to measure the next line's indentation WITHOUT consuming the newline.
    // This allows us to generate DEDENT tokens proactively.
    // 
    // WHEN THIS HAPPENS:
    // - We're currently not at line start (in middle of previous line)
    // - Parser wants DEDENT but doesn't want NEWLINE  
    // - We encounter a newline character
    // 
    // EXAMPLE SCENARIO:
    //   config =
    //     server = localhost
    //     port = 8080
    //   # <- Parser needs DEDENT here before processing the comment
    //   comment = "..."
    // 
    // Without lookahead, we'd return NEWLINE first, but parser wants DEDENT first.
    if ((lexer->lookahead == '\n' || lexer->lookahead == '\r') && valid_symbols[DEDENT] && !valid_symbols[NEWLINE] && !at_line_start) {
      DEBUG_LOG("Phase 3: Lookahead DEDENT - at newline with DEDENT expected but NEWLINE not expected");
      
      // LOOKAHEAD ALGORITHM:
      // 1. Temporarily skip past the newline (consuming it)
      // 2. Measure the next line's indentation  
      // 3. Compare with current indentation level
      // 4. Generate DEDENT tokens if next line has less indentation
      // 5. Let the parser handle the newline in a subsequent call
      
      // Step 1: Skip past the current newline temporarily
      // NOTE: We consume the newline here because tree-sitter's lexer doesn't
      // support true lookahead - once we advance, we can't go back
      if (lexer->lookahead == '\r') {
        lexer->advance(lexer, false);  // Skip \r
        if (lexer->lookahead == '\n') {
          lexer->advance(lexer, false);  // Skip \n after \r
        }
      } else {
        lexer->advance(lexer, false);  // Skip \n
      }
      
      // Step 2: Measure next line's indentation using same algorithm as main phase
      // CRITICAL: This calculation must match the indentation measurement in Phase 4
      uint16_t next_indent = 0;
      while (lexer->lookahead == ' ' || lexer->lookahead == '\t') {
        if (lexer->lookahead == ' ') {
          next_indent++;  // Each space = 1 indentation unit
        } else if (lexer->lookahead == '\t') {
          next_indent += 8;  // Each tab = 8 indentation units (must match line 133)
        }
        lexer->advance(lexer, false);
      }
      
      // Step 3: Compare with current indentation level (top of stack)
      uint16_t current_stack_top = indent_stack.back();
      DEBUG_LOG("Phase 3: Next line indent=%d, current stack top=%d", next_indent, current_stack_top);
      
      // Step 4: Generate DEDENT tokens if next line has less indentation
      if (next_indent < current_stack_top) {
        DEBUG_LOG("Phase 3: Next line has less indentation, generating DEDENT tokens");
        
        // DEDENT GENERATION ALGORITHM:
        // Pop all indentation levels greater than the next line's indentation
        // Each popped level generates one DEDENT token
        // Example: Stack [0,4,8], next_indent=2 -> pop 8,4 -> generate 2 DEDENTs, push 2
        while (!indent_stack.empty() && indent_stack.back() > next_indent) {
          uint16_t popped_level = indent_stack.back();
          indent_stack.pop_back();
          pending_tokens.push(DEDENT);
          DEBUG_LOG("Phase 3: Popped level %d, queued DEDENT (stack size now: %zu)", popped_level, indent_stack.size());
          (void)popped_level;  // Suppress unused variable warning when DEBUG_LOG is disabled
        }
        
        // Ensure the next indentation level is in our stack for future comparisons
        // This handles cases where the indentation decreases to a level we haven't seen before
        if (indent_stack.empty() || indent_stack.back() != next_indent) {
          indent_stack.push_back(next_indent);
          DEBUG_LOG("Phase 3: Pushed new indentation level %d to stack", next_indent);
        }
        
        // Return the first DEDENT token, others remain queued for subsequent calls
        if (!pending_tokens.empty()) {
          TokenType token = pending_tokens.front();
          pending_tokens.pop();
          DEBUG_LOG("Phase 3: Returning lookahead DEDENT token (parser will handle newline later)");
          lexer->result_symbol = token;
          return true;
        }
      } else {
        DEBUG_LOG("Phase 3: Next line indentation same or greater (%d >= %d), no DEDENT needed", 
                  next_indent, current_stack_top);
      }
    }

    // PHASE 4: Main indentation analysis - Core algorithm
    // ===================================================
    // This is the primary indentation handling logic, executed when we're at
    // the start of a line (after a NEWLINE token or at file beginning).
    // 
    // ALGORITHM:
    // 1. Measure current line's indentation (spaces + tabs*8)
    // 2. Compare with previous indentation level (top of indent_stack)
    // 3. Generate appropriate tokens:
    //    - Increase: Push new level to stack, generate INDENT
    //    - Decrease: Pop levels from stack, generate DEDENT(s)
    //    - Same: No tokens generated
    // 4. Update state for next scan() call
    // 
    // INDENTATION MEASUREMENT:
    // - Each space character = 1 indentation unit
    // - Each tab character = 8 indentation units (standard terminal width)
    // - Mixed spaces/tabs are allowed but discouraged for readability
    // 
    // STACK MANAGEMENT:
    // The indent_stack maintains the history of nested indentation levels:
    //   [0] -> base level (always present)
    //   [0,2] -> nested 2 spaces deep  
    //   [0,2,6] -> nested 2, then 6 spaces deep
    // This allows proper DEDENT generation when closing multiple levels.
    if (at_line_start) {
      // Step 1: Measure current line's indentation
      // This is the canonical indentation measurement algorithm used throughout the scanner
      current_indent = 0;
      while (lexer->lookahead == ' ' || lexer->lookahead == '\t') {
        if (lexer->lookahead == ' ') {
          current_indent++;  // Each space = 1 indentation unit
        } else if (lexer->lookahead == '\t') {
          current_indent += 8;  // Each tab = 8 indentation units (MUST match line 90)
        }
        lexer->advance(lexer, false);  // Consume whitespace characters
      }
      
      // Step 2: Update state and get previous indentation for comparison
      at_line_start = false;  // We're no longer at line start after measuring indentation
      uint16_t previous_indent = indent_stack.back();  // Current expected indentation level
      
      DEBUG_LOG("Phase 4: Measured indentation - current=%d, previous=%d, stack=%zu", 
                current_indent, previous_indent, indent_stack.size());
      
      // Step 3a: Handle INDENT - indentation increased (new nested block)
      if (current_indent > previous_indent && valid_symbols[INDENT]) {
        DEBUG_LOG("Phase 4: Indentation INCREASED (%d -> %d), opening new block", previous_indent, current_indent);
        indent_stack.push_back(current_indent);  // Push new indentation level to stack
        lexer->result_symbol = INDENT;
        DEBUG_LOG("Phase 4: Generated INDENT token, stack now: %zu levels", indent_stack.size());
        return true;
      } 
      
      // Step 3b: Handle DEDENT - indentation decreased (closing nested blocks)
      else if (current_indent < previous_indent && valid_symbols[DEDENT]) {
        DEBUG_LOG("Phase 4: Indentation DECREASED (%d -> %d), closing block(s)", previous_indent, current_indent);
        
        // MULTI-LEVEL DEDENT ALGORITHM:
        // When indentation decreases, we might be closing multiple nested levels at once.
        // Example: Indentation goes from 8 to 0, we need to close levels 8, 4, 2
        // Each closed level generates one DEDENT token.
        
        // Pop all indentation levels greater than current indentation
        while (!indent_stack.empty() && indent_stack.back() > current_indent) {
          uint16_t closed_level = indent_stack.back();
          indent_stack.pop_back();
          pending_tokens.push(DEDENT);
          DEBUG_LOG("Phase 4: Closed indentation level %d, queued DEDENT (stack size: %zu)", 
                    closed_level, indent_stack.size());
          (void)closed_level;  // Suppress unused variable warning when DEBUG_LOG is disabled
        }
        
        // Ensure the current indentation level is in our stack for future comparisons
        // This handles cases where indentation decreases to a previously unseen level
        if (indent_stack.empty() || indent_stack.back() != current_indent) {
          indent_stack.push_back(current_indent);
          DEBUG_LOG("Phase 4: Added new indentation level %d to stack", current_indent);
        }
        
        // Return the first DEDENT token, others remain queued
        if (!pending_tokens.empty()) {
          TokenType token = pending_tokens.front();
          pending_tokens.pop();
          DEBUG_LOG("Phase 4: Returning first DEDENT token (%zu more queued)", pending_tokens.size());
          lexer->result_symbol = token;
          return true;
        }
      }
    }

    // PHASE 5: End-of-file cleanup - Critical for parser correctness
    // ==============================================================
    // When we reach EOF, we must generate DEDENT tokens for all remaining
    // indentation levels to properly close any open blocks. This prevents
    // parse errors when files don't end with explicit dedentation to column 0.
    // 
    // EXAMPLE:
    //   config =
    //     server =
    //       host = localhost
    //       port = 8080
    //   # EOF here - need 2 DEDENTs to close 'server' and 'config' blocks
    // 
    // We keep the base level (indent_stack[0] = 0) and only generate DEDENTs
    // for levels above it, since the base level represents the file scope.
    if (lexer->lookahead == 0 && indent_stack.size() > 1 && valid_symbols[DEDENT]) {
      DEBUG_LOG("Phase 5: EOF detected with %zu indentation levels, generating cleanup DEDENTs", 
                indent_stack.size() - 1);  // -1 because we keep base level
      
      // Generate DEDENT for each indentation level except the base (level 0)
      while (indent_stack.size() > 1) {
        uint16_t closing_level = indent_stack.back();
        indent_stack.pop_back();
        pending_tokens.push(DEDENT);
        DEBUG_LOG("Phase 5: EOF closing level %d, queued DEDENT (stack size: %zu)", 
                  closing_level, indent_stack.size());
        (void)closing_level;  // Suppress unused variable warning when DEBUG_LOG is disabled
      }
      
      // Return the first EOF DEDENT token
      if (!pending_tokens.empty()) {
        TokenType token = pending_tokens.front();
        pending_tokens.pop();
        DEBUG_LOG("Phase 5: Returning EOF DEDENT token (%zu more queued)", pending_tokens.size());
        lexer->result_symbol = token;
        return true;
      }
    }

    // PHASE 6: State cleanup and fallthrough handling
    // ===============================================
    // If we reach here without generating a token, clean up any inconsistent
    // state before returning false to let the main parser handle the character.
    
    // Reset at_line_start flag if we encounter non-whitespace at line start
    // This can happen if the parser didn't expect INDENT/DEDENT tokens
    if (at_line_start && lexer->lookahead != ' ' && lexer->lookahead != '\t' && 
        lexer->lookahead != '\n' && lexer->lookahead != '\r' && lexer->lookahead != 0) {
      DEBUG_LOG("Phase 6: Non-whitespace at line start, resetting at_line_start flag");
      at_line_start = false;
    }

    DEBUG_LOG("Phase 6: No external scanner token matched, deferring to main parser");
    return false;  // Let the main parser handle this character
  }

  /**
   * Serialize scanner state for incremental parsing support.
   * 
   * Tree-sitter calls this function when text changes to save the parser state,
   * enabling efficient re-parsing of only the modified sections. The serialized
   * state must contain enough information to restore the scanner to exactly
   * the same condition.
   * 
   * SERIALIZATION FORMAT (binary, little-endian):
   * =============================================
   * [0x00]      at_line_start flag (1 byte: 0x00=false, 0x01=true)
   * [0x01-0x02] current_indent value (2 bytes: uint16_t)
   * [0x03-0x04] indent_stack size (2 bytes: uint16_t count)
   * [0x05-...] indent_stack contents (2 bytes per level: uint16_t[])
   * [...-...]   pending_tokens size (2 bytes: uint16_t count)
   * 
   * IMPORTANT DECISIONS:
   * - pending_tokens contents are NOT serialized (only size for debugging)
   * - This is correct because pending tokens represent transient state that
   *   should be consumed immediately, not persisted across parsing sessions
   * - Maximum serialization size is limited to prevent buffer overflow
   * 
   * @param buffer - Output buffer for serialized state (provided by tree-sitter)
   * @return Number of bytes written to buffer
   */
  unsigned serialize(char *buffer) {
    DEBUG_LOG("=== serialize() called ===");
    unsigned offset = 0;
    
    // Serialize at_line_start flag (1 byte)
    buffer[offset] = at_line_start ? 1 : 0;
    offset++;
    DEBUG_LOG("Serialized at_line_start: %d", at_line_start);
    
    // Serialize current_indent value (2 bytes)
    memcpy(buffer + offset, &current_indent, sizeof(uint16_t));
    offset += sizeof(uint16_t);
    DEBUG_LOG("Serialized current_indent: %d", current_indent);
    
    // Serialize indent_stack size (2 bytes)
    uint16_t stack_size = static_cast<uint16_t>(indent_stack.size());
    memcpy(buffer + offset, &stack_size, sizeof(uint16_t));
    offset += sizeof(uint16_t);
    DEBUG_LOG("Serialized stack_size: %d", stack_size);
    
    // Serialize indent_stack contents (2 bytes per level)
    for (size_t i = 0; i < indent_stack.size(); i++) {
      if (offset + sizeof(uint16_t) >= 1024) {
        DEBUG_LOG("WARNING: Truncating stack serialization to prevent buffer overflow");
        break; // Prevent buffer overflow (tree-sitter typically provides 1024 byte buffer)
      }
      memcpy(buffer + offset, &indent_stack[i], sizeof(uint16_t));
      offset += sizeof(uint16_t);
      DEBUG_LOG("Serialized stack[%zu]: %d", i, indent_stack[i]);
    }
    
    // Serialize pending_tokens size for debugging (2 bytes)
    // NOTE: We intentionally do NOT serialize the pending token contents because:
    // 1. They represent transient state that should be consumed immediately
    // 2. They should not persist across different parsing sessions  
    // 3. Deserialize will always clear them anyway
    uint16_t pending_size = static_cast<uint16_t>(pending_tokens.size());
    memcpy(buffer + offset, &pending_size, sizeof(uint16_t));
    offset += sizeof(uint16_t);
    DEBUG_LOG("Serialized pending_tokens size (for debugging): %d", pending_size);
    
    DEBUG_LOG("Serialization complete: %d total bytes", offset);
    return offset;
  }

  /**
   * Restore scanner state from previously serialized data.
   * 
   * This function reconstructs the scanner's internal state from binary data
   * created by serialize(). It must handle various edge cases gracefully,
   * including empty buffers, truncated data, and corrupted input.
   * 
   * DESERIALIZATION STRATEGY:
   * ========================
   * 1. Handle empty buffer by resetting to initial state
   * 2. Parse each field with bounds checking to prevent buffer overruns
   * 3. Ensure critical invariants are maintained (base indentation level)
   * 4. Clear transient state (pending tokens)
   * 
   * INVARIANTS MAINTAINED:
   * ======================
   * - indent_stack always contains at least base level (0)
   * - pending_tokens is always cleared (transient state)
   * - All numeric values are within reasonable ranges
   * 
   * @param buffer - Input buffer containing serialized state
   * @param length - Size of input buffer in bytes
   */
  void deserialize(const char *buffer, unsigned length) {
    DEBUG_LOG("=== deserialize() called with %d bytes ===", length);
    
    // Handle empty buffer gracefully - reset to initial state
    if (length == 0) {
      DEBUG_LOG("Empty buffer detected, resetting to initial state");
      at_line_start = true;
      current_indent = 0;
      indent_stack.clear();
      indent_stack.push_back(0);  // CRITICAL: Always maintain base level
      while (!pending_tokens.empty()) pending_tokens.pop();
      DEBUG_LOG("Reset complete: initial state restored");
      return;
    }
    
    unsigned offset = 0;
    
    // Deserialize at_line_start flag (1 byte)
    if (offset < length) {
      at_line_start = buffer[offset] == 1;
      offset++;
      DEBUG_LOG("Deserialized at_line_start: %d", at_line_start);
    }
    
    // Deserialize current_indent value (2 bytes)
    if (offset + sizeof(uint16_t) <= length) {
      memcpy(&current_indent, buffer + offset, sizeof(uint16_t));
      offset += sizeof(uint16_t);
      DEBUG_LOG("Deserialized current_indent: %d", current_indent);
    }
    
    // Deserialize indent_stack (variable length)
    if (offset + sizeof(uint16_t) <= length) {
      uint16_t stack_size;
      memcpy(&stack_size, buffer + offset, sizeof(uint16_t));
      offset += sizeof(uint16_t);
      DEBUG_LOG("Deserializing indent_stack with %d levels", stack_size);
      
      indent_stack.clear();
      
      // Restore each indentation level with bounds checking
      for (uint16_t i = 0; i < stack_size && offset + sizeof(uint16_t) <= length; i++) {
        uint16_t indent_level;
        memcpy(&indent_level, buffer + offset, sizeof(uint16_t));
        indent_stack.push_back(indent_level);
        offset += sizeof(uint16_t);
        DEBUG_LOG("Restored indent_stack[%d]: %d", i, indent_level);
      }
      
      // CRITICAL INVARIANT: Ensure we always have at least the base level
      // This prevents stack underflow in subsequent operations
      if (indent_stack.empty()) {
        DEBUG_LOG("WARNING: Empty indent_stack after deserialization, adding base level");
        indent_stack.push_back(0); // Base level for safety
      }
    }
    
    // Always clear pending tokens - they represent transient state
    // that should not persist across parsing sessions
    while (!pending_tokens.empty()) pending_tokens.pop();
    DEBUG_LOG("Cleared pending_tokens (transient state)");
    
    // Skip pending_tokens size if present (it was only for debugging)
    if (offset + sizeof(uint16_t) <= length) {
      uint16_t pending_size;
      memcpy(&pending_size, buffer + offset, sizeof(uint16_t));
      DEBUG_LOG("Skipped pending_tokens size from serialization: %d", pending_size);
    }
    
    DEBUG_LOG("Deserialization complete: at_line_start=%d, current_indent=%d, stack_size=%zu", 
              at_line_start, current_indent, indent_stack.size());
  }
};

} // namespace

/**
 * C ABI Interface for Tree-sitter Integration
 * ===========================================
 * 
 * Tree-sitter requires external scanners to provide a specific C interface
 * with these exact function names and signatures. The tree-sitter runtime
 * calls these functions to manage scanner lifecycle and token generation.
 * 
 * FUNCTION CALL PATTERN:
 * 1. tree_sitter_ccl_external_scanner_create() - Once at parser initialization
 * 2. tree_sitter_ccl_external_scanner_scan() - For each potential token
 * 3. tree_sitter_ccl_external_scanner_serialize/deserialize() - During incremental parsing
 * 4. tree_sitter_ccl_external_scanner_destroy() - Once at parser cleanup
 * 
 * NAMING CONVENTION:
 * Function names must follow the pattern: tree_sitter_LANGUAGE_external_scanner_FUNCTION
 * where LANGUAGE matches the grammar name in grammar.js
 */
extern "C" {

/**
 * Create and initialize a new scanner instance.
 * 
 * Called once when the tree-sitter parser is initialized. Must return
 * a pointer to scanner state that will be passed to all other functions.
 * 
 * @return Pointer to new Scanner instance (cast to void*)
 */
void *tree_sitter_ccl_external_scanner_create() {
  DEBUG_LOG("=== Creating external scanner instance ===");
  return new Scanner();
}

/**
 * Destroy scanner instance and free associated memory.
 * 
 * Called once when the tree-sitter parser is destroyed. Must properly
 * clean up all resources allocated by the scanner.
 * 
 * @param payload - Scanner instance pointer from create() function
 */
void tree_sitter_ccl_external_scanner_destroy(void *payload) {
  DEBUG_LOG("=== Destroying external scanner instance ===");
  delete static_cast<Scanner*>(payload);
}

/**
 * Serialize scanner state for incremental parsing.
 * 
 * Called by tree-sitter when text changes to save parser state.
 * This enables efficient re-parsing by restoring state at change boundaries.
 * 
 * @param payload - Scanner instance pointer
 * @param buffer - Output buffer for serialized state (typically 1024 bytes)
 * @return Number of bytes written to buffer
 */
unsigned tree_sitter_ccl_external_scanner_serialize(void *payload, char *buffer) {
  Scanner *scanner = static_cast<Scanner*>(payload);
  return scanner->serialize(buffer);
}

/**
 * Restore scanner state from serialized data.
 * 
 * Called by tree-sitter to restore scanner state during incremental parsing.
 * Must restore the scanner to exactly the same state as when serialized.
 * 
 * @param payload - Scanner instance pointer
 * @param buffer - Input buffer containing serialized state
 * @param length - Size of input buffer in bytes
 */
void tree_sitter_ccl_external_scanner_deserialize(void *payload, const char *buffer, unsigned length) {
  Scanner *scanner = static_cast<Scanner*>(payload);
  scanner->deserialize(buffer, length);
}

/**
 * Main token generation function - the heart of the external scanner.
 * 
 * Called by tree-sitter whenever it needs to check for external tokens.
 * This is where the core indentation parsing logic is executed.
 * 
 * @param payload - Scanner instance pointer
 * @param lexer - Tree-sitter lexer interface for character access
 * @param valid_symbols - Boolean array indicating which tokens parser expects
 * @return true if a token was generated, false to defer to main parser
 */
bool tree_sitter_ccl_external_scanner_scan(void *payload, TSLexer *lexer, const bool *valid_symbols) {
  Scanner *scanner = static_cast<Scanner*>(payload);
  return scanner->scan(lexer, valid_symbols);
}

} // extern "C"